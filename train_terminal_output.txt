/Users/dbaeka/miniconda3/bin/python /Users/dbaeka/Documents/School/CU/Winter 2025/COMP6721 Applied AI/Research/Phase 1/train.py
------------------Group Members------------------------
Delmwin Baeka (40277017)
Lordina Nkansah (40293731)
Anjolaoluwa Lasekan (40294470)
=== Indoor vs Outdoor Image Classification Training ===

Step 1: Loading and preprocessing images...
Visualize sample images...

Processing 5000 indoor images using 12 processes...
100%|██████████| 5000/5000 [00:03<00:00, 1370.71it/s]
  0%|          | 0/5000 [00:00<?, ?it/s]
Processing 5000 outdoor images using 12 processes...
100%|██████████| 5000/5000 [00:02<00:00, 2357.47it/s]

Step 2: Performing exploratory data analysis...
Dataset shape: (10000, 1876)
Number of indoor images: 5000
Number of outdoor images: 5000

Top 10 features correlated with target:
class           1.000000
feature_1874    0.499323
feature_1875    0.454567
feature_95      0.330044
feature_1872    0.326534
feature_94      0.271131
feature_93      0.255747
feature_1127    0.249538
feature_622     0.247260
feature_1350    0.247045
Name: class, dtype: float64

Data split: 8000 training samples, 2000 testing samples
Transform successfully saved to the 'feature_transforms' directory
Reduced from 1876 to 1876 dimensions
Number of components to retain 95% variance: 513
Reduced from 1876 to 513 dimensions
Transform successfully saved to the 'feature_transforms' directory

Step 3: Training and optimizing models...

=== Decision Tree Classifier ===

Hyperparameter tuning results for Decision Tree:
  param_max_depth param_min_samples_split param_min_samples_leaf  \
5               5                       2                      5
2              10                       2                      5
9              10                      10                      5
4               5                       2                     10
3              15                       2                     10
8            None                      10                     10
0            None                       2                      5
6              15                      20                      1
1            None                       2                     10
7              15                      10                      1

   mean_test_score  std_test_score
5         0.752625        0.010454
2         0.712625        0.014713
9         0.712625        0.014713
4         0.659000        0.008529
3         0.633625        0.014017
8         0.619250        0.019896
0         0.609500        0.012756
6         0.573250        0.021885
1         0.569375        0.014334
7         0.551875        0.013428
Best parameters: {'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': 5, 'criterion': 'entropy'}
Best cross-validation score: 0.7526
Models successfully saved to the 'models' directory

=== Random Forest Classifier ===

Hyperparameter tuning results for Random Forest:
  param_n_estimators param_max_depth param_min_samples_split  \
2                200              30                      20
6                100              20                       2
7                200              10                      10
0                200              30                      10
3                 50              10                      20
8                 50              20                      20
1                100              20                      10
5                100              10                      20
4                 50            None                       2
9                100              30                      20

  param_min_samples_leaf  mean_test_score  std_test_score
2                     10         0.845375        0.008049
6                     10         0.830500        0.007452
7                     10         0.820250        0.009191
0                      5         0.811500        0.008729
3                     10         0.810750        0.010907
8                      5         0.804375        0.008178
1                      1         0.803125        0.009977
5                      5         0.802250        0.012302
4                     10         0.801125        0.008528
9                      1         0.787750        0.006586
Best parameters: {'n_estimators': 200, 'min_samples_split': 20, 'min_samples_leaf': 10, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy'}
Best cross-validation score: 0.8454
Models successfully saved to the 'models' directory

=== Gradient Boosting Classifier ===

Hyperparameter tuning results for Gradient Boosting:
  param_n_estimators param_learning_rate param_max_depth param_subsample  \
7                200                 0.1               5             0.8
4                200                 0.1               3             0.8
5                100                 0.2               3             0.8
1                100                 0.2               7             0.8
9                 50                 0.2               5             0.8
6                200                0.01               5             0.8
8                 50                0.01               7             0.8
2                 50                0.01              10             0.8
0                200                0.01               3             0.8
3                 50                0.01               3             0.8

   mean_test_score  std_test_score
7         0.872750        0.007327
4         0.865750        0.006643
5         0.858250        0.004633
1         0.854500        0.004497
9         0.853250        0.006512
6         0.820250        0.008087
8         0.801250        0.011436
2         0.799875        0.010639
0         0.799125        0.007812
3         0.766250        0.012349
Best parameters: {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1}
Best cross-validation score: 0.8727
Models successfully saved to the 'models' directory

=== Semi-Supervised Learning w Decision Tree ===

--- Iteration 1 ---

Hyperparameter tuning results for Decision Tree Iteration:
  param_max_depth param_min_samples_split param_min_samples_leaf  \
5               5                       2                      5
2              10                       2                      5
9              10                      10                      5
4               5                       2                     10
0            None                       2                      5
8            None                      10                     10
3              15                       2                     10
7              15                      10                      1
1            None                       2                     10
6              15                      20                      1

   mean_test_score  std_test_score
5         0.711250        0.013199
2         0.680000        0.014470
9         0.680000        0.014470
4         0.645000        0.029222
0         0.601875        0.018604
8         0.585000        0.018477
3         0.582500        0.019223
7         0.568125        0.042546
1         0.561875        0.018895
6         0.555000        0.017522
Best parameters: {'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': 5, 'criterion': 'entropy'}
Best cross-validation score: 0.7112
Number of high-confidence pseudo-labels: 3433

--- Iteration 2 ---

Hyperparameter tuning results for Decision Tree Iteration:
  param_max_depth param_min_samples_split param_min_samples_leaf  \
5               5                       2                      5
2              10                       2                      5
9              10                      10                      5
3              15                       2                     10
8            None                      10                     10
0            None                       2                      5
4               5                       2                     10
1            None                       2                     10
6              15                      20                      1
7              15                      10                      1

   mean_test_score  std_test_score
5         0.928301        0.090504
2         0.907635        0.086329
9         0.907635        0.086329
3         0.727006        0.032874
8         0.718872        0.042536
0         0.694622        0.061411
4         0.692805        0.087329
1         0.602439        0.037300
6         0.579572        0.031401
7         0.566070        0.030237
Best parameters: {'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': 5, 'criterion': 'entropy'}
Best cross-validation score: 0.9283
Number of high-confidence pseudo-labels: 458

--- Iteration 3 ---

Hyperparameter tuning results for Decision Tree Iteration:
  param_max_depth param_min_samples_split param_min_samples_leaf  \
5               5                       2                      5
2              10                       2                      5
9              10                      10                      5
4               5                       2                     10
3              15                       2                     10
0            None                       2                      5
8            None                      10                     10
6              15                      20                      1
7              15                      10                      1
1            None                       2                     10

   mean_test_score  std_test_score
5         0.935195        0.085368
2         0.897493        0.079963
9         0.897493        0.079963
4         0.772919        0.057813
3         0.712263        0.025987
0         0.706077        0.051027
8         0.702790        0.044089
6         0.632139        0.054231
7         0.608988        0.022863
1         0.604634        0.052546
Best parameters: {'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': 5, 'criterion': 'entropy'}
Best cross-validation score: 0.9352
Number of high-confidence pseudo-labels: 589

--- Iteration 4 ---

Hyperparameter tuning results for Decision Tree Iteration:
  param_max_depth param_min_samples_split param_min_samples_leaf  \
5               5                       2                      5
2              10                       2                      5
9              10                      10                      5
4               5                       2                     10
8            None                      10                     10
3              15                       2                     10
0            None                       2                      5
6              15                      20                      1
7              15                      10                      1
1            None                       2                     10

   mean_test_score  std_test_score
5         0.932895        0.085161
2         0.912664        0.081320
9         0.912664        0.081320
4         0.756414        0.077183
8         0.741941        0.050570
3         0.740625        0.064617
0         0.727303        0.039599
6         0.658224        0.060375
7         0.602467        0.021923
1         0.576809        0.034706
Best parameters: {'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': 5, 'criterion': 'entropy'}
Best cross-validation score: 0.9329
Number of high-confidence pseudo-labels: 3

--- Iteration 5 ---

Hyperparameter tuning results for Decision Tree Iteration:
  param_max_depth param_min_samples_split param_min_samples_leaf  \
5               5                       2                      5
2              10                       2                      5
9              10                      10                      5
4               5                       2                     10
8            None                      10                     10
3              15                       2                     10
0            None                       2                      5
6              15                      20                      1
7              15                      10                      1
1            None                       2                     10

   mean_test_score  std_test_score
5         0.930154        0.090213
2         0.911409        0.081514
9         0.911409        0.081514
4         0.756395        0.077224
8         0.734196        0.073873
3         0.720718        0.066337
0         0.710845        0.045023
6         0.649208        0.055889
7         0.605456        0.021677
1         0.566163        0.028113
Best parameters: {'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': 5, 'criterion': 'entropy'}
Best cross-validation score: 0.9302
Number of high-confidence pseudo-labels: 1

Hyperparameter tuning results for Decision Tree Iteration:
  param_max_depth param_min_samples_split param_min_samples_leaf  \
5               5                       2                      5
2              10                       2                      5
9              10                      10                      5
4               5                       2                     10
3              15                       2                     10
8            None                      10                     10
0            None                       2                      5
6              15                      20                      1
7              15                      10                      1
1            None                       2                     10

   mean_test_score  std_test_score
5         0.929991        0.090097
2         0.911249        0.081434
9         0.911249        0.081434
4         0.756429        0.077076
3         0.739491        0.081285
8         0.721574        0.065330
0         0.719764        0.050526
6         0.650566        0.071093
7         0.629216        0.075044
1         0.578395        0.033958
Best parameters: {'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': 5, 'criterion': 'entropy'}
Best cross-validation score: 0.9300
Models successfully saved to the 'models' directory

Step 4: Evaluating models...

--- Decision Tree Evaluation Metrics ---
Accuracy: 0.7535
Precision: 0.7777
Recall: 0.7100
F1 Score: 0.7423

Classification Report:
              precision    recall  f1-score   support

      Indoor       0.73      0.80      0.76      1000
     Outdoor       0.78      0.71      0.74      1000

    accuracy                           0.75      2000
   macro avg       0.76      0.75      0.75      2000
weighted avg       0.76      0.75      0.75      2000


--- Random Forest Evaluation Metrics ---
Accuracy: 0.8610
Precision: 0.8800
Recall: 0.8360
F1 Score: 0.8574

Classification Report:
              precision    recall  f1-score   support

      Indoor       0.84      0.89      0.86      1000
     Outdoor       0.88      0.84      0.86      1000

    accuracy                           0.86      2000
   macro avg       0.86      0.86      0.86      2000
weighted avg       0.86      0.86      0.86      2000


--- Gradient Boosting Evaluation Metrics ---
Accuracy: 0.8710
Precision: 0.8770
Recall: 0.8630
F1 Score: 0.8700

Classification Report:
              precision    recall  f1-score   support

      Indoor       0.87      0.88      0.87      1000
     Outdoor       0.88      0.86      0.87      1000

    accuracy                           0.87      2000
   macro avg       0.87      0.87      0.87      2000
weighted avg       0.87      0.87      0.87      2000


--- Semi-Supervised Decision Tree Evaluation Metrics ---
Accuracy: 0.7400
Precision: 0.7321
Recall: 0.7570
F1 Score: 0.7443

Classification Report:
              precision    recall  f1-score   support

      Indoor       0.75      0.72      0.74      1000
     Outdoor       0.73      0.76      0.74      1000

    accuracy                           0.74      2000
   macro avg       0.74      0.74      0.74      2000
weighted avg       0.74      0.74      0.74      2000


Step 5: Comparing model performance...

=== Model Performance Summary ===
                               Accuracy  Precision  Recall  F1 Score
Decision Tree                    0.7535   0.777656   0.710  0.742290
Random Forest                    0.8610   0.880000   0.836  0.857436
Gradient Boosting                0.8710   0.877033   0.863  0.869960
Semi-Supervised Decision Tree    0.7400   0.732108   0.757  0.744346

Best model based on F1 score: Gradient Boosting

=== Classification Project Complete ===

Process finished with exit code 0
